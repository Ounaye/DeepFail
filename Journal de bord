------------JOURNAL DE BORD---------------

18/01/2021 :
Début de projet, Tp de Base python (sklearn), quelques idées
Comment analyser les images ?
- Code Python afin de récupérer toutes les informations de couleurs d'une image -> scatter
- from PIL import Image -> r.histogram()

(Yannis) : J'ai traité les données en fonction de leur nombre maximum de couleur
Et je l'ai ai mise en format pour que l'on puisse appliquer les algorithmes vues en cours
Fichier de programme principale modifier
Pour récupérer l'ensemble des fichiers je me suis appuyer sur ce lien :  https://docs.python.org/fr/3.6/library/glob.html
On obtient un résultat de 0,58 donc très mauvais comme attendu

19/01 :

(Yannis) : J'ai implémenter une seconde qui utilise les histogrammes de couleur,j'arrive toujours sur de très mauvais résultat
J'ai regardé le jeu de donnés et j'ai remarquer que si on arrive à dire si une image est bleu ou pas c'est déjà bien
Donc j'ai essayer de faire ça, mais la manière dont on récupère les images est pas super
J'en ai trouver une autre qui me parait plus flexible qui utilise skimage.
Il y a une erreur dans le jeu de donné : Mer_3 pillq

A faire : Utiliser cette nouvelle manière de prendre les images plus flexibles pour donner plus d'information à notre fonction gaussienne
Attention donner tout nos pixels n'est pas une option ( beaucoup trop long !! )

(Yannis) : J'ai essayer de faire une analyse simple pixel par pixel de chaque image c'est bien trop long, il va falloir réduire les images
Le code écrit avec les mots BLUE manipule des tableaux en 3 dimensions, ce qui rend la lecture du code compliquer
J'ai aussi mis la partie apprentissage sous forme de fonction pour plus de flexibilité

(Groupe) : 
César : doit trouver des moyens de traiter les couleurs efficacements : Trouver à partir d'un histogramme si il y a une dominance de bleu ou quoi
Yannis : Réduire la quantité de pixel par 25 sur chaque image
Dylan : regarde les moocs de la prof, trouve des ressources, notamment comment trouver des formes sur les images

A finir avant Dimanche 24 janvier

21/01 :

(Yannis) : J'ai clean un peu le code et ajouté une fonction qui redimensionne toutes nos images
J'ai pas eu le temps de tester nos anciens algorithmes dessus

23/01 :

(Dylan) :  J'ai fait différentes recherches sur le traitement d'une image et notamment la détéction de contour. J'ai pu trouver un moyen qui fonctionne au niveau des valeurs RGB d'un pixel. Le code est d'ailleurs détaillé sur un site : "https://cache.media.eduscol.education.fr/file/ISN_Tle_S/27/1/lyceeGT_ressource_ISN_20_06_Tle_S_22_Traitement_images_2_218271.pdf"
J'ai aussi pu trouver un module python sur un autre site qui nous permet de colorer une image afin de détécter les concours, le site contient par ailleurs un code qui fait. Ce site a d'ailleurs un exemple de détection de contours et cek apeut réellement nous aider pour trouver des vagues dans une image (En effet des vagues différencieraient bien n'importe quel point d'eau de la mer).
Nouveau site en question : https://moonbooks.org/Articles/Détecter-les-contours-dune-image-avec-un-filtre-de-Canny-sous-python/

24/01 : 

(Equipe) : On a tester l'algo pour voir si il y a assez de bleu on doit déterminer le Threshold. On a pu monter à des 0.7 de réussite en moyenne
Dylan : Doit faire une fonction qui détermine le Threshold Optimal
Yannis : Faire la fonction de batch des tests
On a eu l'idée ajouter d'autres paramètres d'apprentissages, Il faut consulté les liens de Dylan pour bien les utilisés 

(Dylan) : Implémentation de la méthode findBestTreshold qui prend en argument le début des treshold à tester, et le pas. Cette méthode nous permettra de trouver le Treshold optimal, afin d'obtenir le meilleur score sur notre jeu de donnée.
Méthode qui subira des modifications avec l'ajout des méthodes Kfold de Yannis.

25/01 : 

(Equipe) : Séance en groupe avec le prof, il nous a aiguiller sur de la reconnaissance d'image par convolution, avec gradient etc.. 
Dylan : Implémenter les algo dans cette pages https://learnopencv.com/histogram-of-oriented-gradients/ 
ils vont nous permettre de détecter les contours
Yannis : Faire la fonction de batch des tests

(Dylan) : Implémentation de deux méthodes findOutLinesOfImage, et findOutLinesOfImage2 qui sont censés détecter les contours à l'intérieur des images. Ces méthodes sont obsolètes car soit pas très utile, soit ne fonctionne pas. Je vais donc me concentrer à implémenter la détection de contours d'après l'histogramme de gradients et le filtre de Sobel comme nous l'a conseillé le prof.


29/01 :

(Dylan) : Implémentation de la détéction du contour d'images. J'ai aussi essayé de montrer la différence obtenu lorsqu'on applique cette méthode à une image réduite, et sur une image non réduite.
On observe une grosse différence qualité de contours, qu'on retrouve notamment sur le tableau de Gradient. Cela peut se taduire soit par une mauvaise méthode de ma part (qui n'est pas vraiment la mienne d'ailleurs),
soit cela vient du fait que l'image est réduite, ce qui me prait très plausibke étant donné qu'il est plus difficile de discerner les contpurs d'une image lorsqu'elle est pixélisé.
A disucter donc entre nous, peut-être essayer de moins réduire les images, ou alors détécter les contours avant de les réduire, je ne sais pas ce sont des propositions ^^.

Pour télécharger le module Open source utiliser (ce module apparait dans la page montrée par le prof lors de la séance du 25/01) :
    - Dans l'invite de commande Anaconda, soit CMD.exe Prompt
    - Ecrire les commandes
    -conda update anaconda-navigator  
    -conda update navigator-updater 
    -pip install opencv-python


01/02 : 

(Equipe) : On a implementer la représentation en histogramme de nos gradients de vecteur, on a pas eu le temps de tester ce modèle à l'apprentissage.
On se donne juste comme objectif de nettoyer le code et de revenir lundi avec des idées d'améliorations

07/02 : 

(Yannis) Réorganisation du code en plusieurs fichiers pour plus de lisibilité


08/02:

(Equipe) : On a réussi à corriger le problème au niveau des histogrammes de gradiant. A la fin de la séance le professeur nous a donné une méthode 
qui fait les gradients ainsi que l'histogramme mieux que nous. Les anciennes fonctions sont inutiles. De plus on a écrit un nouveau classifieur basé sur 
les points les plus proches. On a aussi travaillé sur comment faire plusieurs classifieur sur les mêmes ensembles
A faire : 
Dylan Doit implémenter des fonctions qui permettent d'utiliser plusieurs classifieur en même temps
Yannis Doit écrire son classifieur sous forme de classe pour permettre de l'implémenter dans la fonction que va faire Dylan

Note : Yannis ne sauras pas là à la séance du  15/02

14/02 : 

(Yannis) J'ai presque réussi à rendre mon premier classifieur compatible avec la demande. Je suis bloqué sur une syntaxe python que je ne comprend pas.
C'est la ligne 53 du fichier LearnByMiddle. Le tableau Guess contient la prédiction à chaque élement de l'ensemble de test. 
Je ne comprend pas du tout la syntaxe, si il n'arrive pas à trouver l'erreur peut être lui demander d'expliquer ce que veut dire cette syntaxe.
Je comprend qu'il récupère un tableau y qui est une propriété de la classe. Par contre ce y_[guess] je ne le comprend pas.
Voilà, objectif pour toi c'est de faire des apprentissages avec plus d'élements pour chaque image ( tu peux rajouter l'histogramme par exemple )

15\02 :

(Dylan) : implémentation du classifieur ensembliste VotingClassifier, avec les classifieurs DecisionTreeClassifier, GaussianNB, LogisticRegression, LearnByMiddle. 
Beaucoup d'infos obtenus par la prof sur le classifieur ensembliste notamment sur des attributs tels que la manière de voter par les classifieurs, 
ou encore le poids des votes (donner plus d'importances aux classifieurs qui ont de bonnes prédictions).
De plus, j'ai pas mal discuté avec la prof pour essayer de comprendre d'ou venait l'erreur sur la méthode predict.
Effectivement dans l'exemple de la doc y_[closest] parait particulier. En fait closest est une liste d'indice. 
Apparemment un tableau peut prendre une liste d'indices pour récupérer toutes les valeurs de ces indices.
Dans notre cas le tableau guess n'est rempli que de décisions donc de 1 ou de -1, ainsi le tableau y_ ne revoie pas grand chose. 
Par ailleurs la prof a aussi remarqué selon l'exemple de la doc que renvoyer seulement le tableau rendrait la méthode predict bonne.

Je n'avais pas très bien compris ce qu'était mon objectif dans le tableu de bord. J'ai pensé que tu parlais du fait d'aggrandir notre jeu de données avec des images bruitées. C'est ce que je compte faire dans la semaine.

20/02 : 

(Yannis) : J'ai réparer les petites erreurs dans le code. J'ai réussi à faire en sorte que ma classe soit utilisable dans la nouvelle méthode de classification
ensembliste. J'ai fait des tests avec les histogrammes et la couleur bleu et on a des résultats très variables. Je pense qu'avec des poids approprié on devrais
avoir de bon résultats.

07/03 : 

(Yannis) : J'ai oublier de faire mes commits de la semaine dernière. Cette entrée compte pour 2 semaines. J'ai régler les problèmes de normalisation dans le
traitement des données. J'ai aussi ajouter les poids dans le classifieur par vote. De plus j'ai utiliser la Classe Pipeline qui permet, entre autre, de normaliser
nos données une seconde fois, ce qui permet au classifieur Linéaire de converger. De plus j'ai aussi fait un classifieur avec Stacking les résultats me semble similaire
au classifieur avec vote. J'ai aussi essayer d'ajouter des données en plus pour chaque image, notamment le nombre de pixel que l'on peux considérer comme Bleu,Vert
ou Rouge. L'ajout de ces données n'est pas significatif, je pense qu'il faut ce concentrer sur nos méthodes statistiques et agrandir le jeu de données.
J'ai aussi essayer de travailler avec des images 256 par 256 mais cela ne produit pas de bon résultat et est beaucoup plus lent. 

(Equipe) : Structuration du dossier sur Overleaf, répartition des taches et réunion jeudi pour vérifier que tout est bon et programmez le diapo

(13/03) 

(Yannis) Conforme le projet au demande du rendu, rajout d'outils d'analyses des résultats, amélioration des performances à 90 %. Simplification de l'analyse de 
l'image avec juste un histogramme des couleurs ( analyse bien plus rapide des images ).
